version: "3.6"

services:
  dalai-chat-hub-api:
    # image: "ghcr.io/dhruv-bvpdev/dalai-chat-hub-api-llama-2-13b-chat:latest"
    build:
      context: ./api
      dockerfile: 13B.Dockerfile
    restart: on-failure
    environment:
      MODEL: "/models/llama-2-13b-chat.bin"

  dalai-chat-hub-ui:
    image: "ghcr.io/dhruv-bvpdev/dalai-chat-hub-ui:latest"
    ports:
      - 3000:3000
    restart: on-failure
    environment:
      - "OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXX"
      - "OPENAI_API_HOST=http://llama-gpt-api:8000"
      - "DEFAULT_MODEL=/models/llama-2-13b-chat.bin"
      - "WAIT_HOSTS=llama-gpt-api:8000"
      - "WAIT_TIMEOUT=600"
